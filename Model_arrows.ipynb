{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_arrows.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svezden/Machine-Learning/blob/master/Model_arrows.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sAu1J5uXvVg",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional neural network for the classification of arrows\n",
        "\n",
        "In this notebook we will create a model that will learn to identify different arqueological artifacts assigning to them a particular period where they where constructed.\n",
        "\n",
        "## Importing Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRJemyfRBMvn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbc8e959-02ae-4f1f-965c-d73f0d35c8b3"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy3cs7epY-9M",
        "colab_type": "text"
      },
      "source": [
        "Defining local directory where the photos will be stored. The zip files training and validation should contain the training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRqzPN9wYhdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/arrows' # Here we define the local directory where the photos will be stored\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/arrows')\n",
        "local_zip = '/tmp/validation-arrows.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation-arrows')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7uekYXbZ5-s",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o-qUPyfO7Qr8"
      },
      "source": [
        "The contents of the .zip are extracted to the base directory `/tmp/arrows`. Each subdirectory should contain the different labels of the set.\n",
        "\n",
        "### Keep an eye:\n",
        "We do not explicitly label the images. We use ImageGenerator instead. This is coded to read images from subdirectories, and automatically label them from the name of that subdirectory. So, for example, you will have a 'training' directory containing a 'period1' directory and a 'period2' one. ImageGenerator will label the images appropriately using the name of the subdirectory they are in. \n",
        "\n",
        "Let's define each of these directories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gidg_MXvbHuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory with our training horse pictures\n",
        "train_period1_dir = os.path.join('/tmp/arrow/period1')\n",
        "\n",
        "# Directory with our training human pictures\n",
        "train_period2_dir = os.path.join('/tmp/arrow/period2')\n",
        "\n",
        "# And so on, you have to fill in the rest....\n",
        "\n",
        "# Directory with our training horse pictures\n",
        "validation_period1_dir = os.path.join('/tmp/validation-arrows/validation-period1')\n",
        "\n",
        "# Directory with our training human pictures\n",
        "validation_period2_dir = os.path.join('/tmp/validation-arrows/validation-period2')\n",
        "\n",
        "\n",
        "# And so on ....."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkdlebJ3XtXC",
        "colab_type": "text"
      },
      "source": [
        "Class to predefine a desired accuracy. This will help to stop training once the threshold accuracy has been reached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AriHVD-MBV3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.99):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1U33uzbcAwI",
        "colab_type": "text"
      },
      "source": [
        "###Model building.\n",
        "\n",
        "We will use a convolutional neural network as an arquitecture, with three convolutional layers. After we get a handle on the performance of the model we can change the number of layers and the parameters in each layer. \n",
        "We have to build the model according to the number of periods that we want to predict. This parameter is N_periods "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xZm3hV5fqzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_periods = # This number enters as a parameter in the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8IsyEJ6BYJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    #tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    #tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # N_periods output neurons corresponding to the different periods that we want to capture\n",
        "    tf.keras.layers.Dense(N_periods, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzgo70q2dflU",
        "colab_type": "text"
      },
      "source": [
        "Compiling the model we define the loss function tha measures how well the model approximates the data, and the type off optimizer to perform some of the many variants of gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6WDowwmdhN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVhOWAQSeaLk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sn9m9D3UimHM"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "Let's set up data generators that will read pictures in our source folders, convert them to `float32` tensors, and feed them (with their labels) to our network. We'll have one generator for the training images and one for the validation images. Our generators will yield batches of images of size 300x300 and their labels (binary).\n",
        "\n",
        "As is common, we feed the model with the values of the pixel in the image scaled to be between 0 and 1.\n",
        "\n",
        "In Keras this can be done via the `keras.preprocessing.image.ImageDataGenerator` class using the `rescale` parameter. This `ImageDataGenerator` class allows you to instantiate generators of augmented image batches (and their labels) via `.flow(data, labels)` or `.flow_from_directory(directory)`. These generators can then be used with the Keras model methods that accept data generators as inputs: `fit_generator`, `evaluate_generator`, and `predict_generator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhv51bG8glMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/tmp/arrows/',  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=128,\n",
        "        # To handle multiple labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/tmp/validation-arrows/',  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=32,\n",
        "        # To handle multiple labels\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-0Ac4bymLK1",
        "colab_type": "text"
      },
      "source": [
        "### Training the model\n",
        "All the parameters here can be adjusted for better performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-krppHpk9qI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=8,  \n",
        "      epochs=15,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR9S83cxl5AI",
        "colab_type": "text"
      },
      "source": [
        "Running the Model\n",
        "\n",
        "This code allows us to choose 1 or more files from the file system, it will then upload them, and run them through the model, giving an indication of the period of the object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDlycKQDlDp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}